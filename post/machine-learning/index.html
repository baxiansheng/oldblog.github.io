<!doctype html>
<html lang="en-us">
  <head>
    <title>Machine Learning // Welcome to my blog</title>
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.56.3" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="Baxiansheng" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="https://baxiansheng.github.io/css/main.min.f90f5edd436ec7b74ad05479a05705770306911f721193e7845948fb07fe1335.css" />

    
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Machine Learning"/>
<meta name="twitter:description" content="机器学习基础 machine learning 的例子 &gt; -Database mining
-Applications can&rsquo;t program by hand. -Self-customizing programs
机器学习的定义
 &ldquo;A computer program is said to learn from experience E with respect to som task T and some performance measures P, if its performance on T, as measured by P, improves with experience E.&rdquo;
 机器学习的算法
 -Supervised learning -Unsupervised learning -Others: Reinforcement learning, recommender systems.
 对于监督学习
 -Classification problem(分类问题)-预测离散值 -Regression problem(回归问题)-预测连续值"/>

    <meta property="og:title" content="Machine Learning" />
<meta property="og:description" content="机器学习基础 machine learning 的例子 &gt; -Database mining
-Applications can&rsquo;t program by hand. -Self-customizing programs
机器学习的定义
 &ldquo;A computer program is said to learn from experience E with respect to som task T and some performance measures P, if its performance on T, as measured by P, improves with experience E.&rdquo;
 机器学习的算法
 -Supervised learning -Unsupervised learning -Others: Reinforcement learning, recommender systems.
 对于监督学习
 -Classification problem(分类问题)-预测离散值 -Regression problem(回归问题)-预测连续值" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://baxiansheng.github.io/post/machine-learning/" />
<meta property="article:published_time" content="2019-08-21T20:51:22+08:00" />
<meta property="article:modified_time" content="2019-08-21T20:51:22+08:00" />


  </head>
  <body>
    <header class="app-header">
      <a href="https://baxiansheng.github.io/"><img class="app-header-avatar" src="/avatar.jpg" alt="Baxiansheng" /></a>
      <h1>Welcome to my blog</h1>
      <p>A personal blog for baxiansheng.</p>
      <div class="app-header-social">
        
          <a target="_blank" href="https://github.com/baxiansheng"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-github">
  <title>github</title>
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path>
</svg></a>
        
          <a target="_blank" href="https://twitter.com/gohugoio"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-link">
  <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path>
  <path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path>
</svg></a>
        
      </div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">Machine Learning</h1>
      <div class="post-meta">
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          Aug 21, 2019
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          1 min read
        </div><div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tag">
  <title>tag</title>
  <path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line>
</svg>
          <a class="tag" href="https://baxiansheng.github.io/tags/study/">study</a></div></div>
    </header>
    <div class="post-content">
      

<h2 id="机器学习基础">机器学习基础</h2>

<p>machine learning 的例子
&gt; -Database mining</p>

<p>-Applications can&rsquo;t program by hand.
-Self-customizing programs</p>

<p>机器学习的定义</p>

<blockquote>
<p>&ldquo;A computer program is said to learn from experience E with respect to som task T and some performance measures P, if its performance on T, as measured by P, improves with experience E.&rdquo;</p>
</blockquote>

<p>机器学习的算法</p>

<blockquote>
<p>-Supervised learning
-Unsupervised learning
-Others: Reinforcement learning, recommender systems.</p>
</blockquote>

<p>对于监督学习</p>

<blockquote>
<p>-Classification problem(分类问题)-预测离散值
-Regression problem(回归问题)-预测连续值</p>
</blockquote>

<p>对于非监督学习</p>

<blockquote>
<p>-聚类算法
-鸡尾酒胡算法:
[W,s,v]=svd((repmat(sum(x.*x,1),size(x,1),1).*x)*x&rsquo;);</p>
</blockquote>

<p>在这个监督学习中的回归问题中，有几个基本的概念，如假设函数h(x)(hypothesis),代价函数J(θ)(cost function)等，注意到假设函数是关于x的一个函数，代价函数是关于θ的一个函数。</p>

<p>梯度下降算法
<img src="D:somethingformyblogmyblogresources_genimages梯度下降算法.png" alt="梯度下降" /></p>

<p>线性回归算法
<img src="D:somethingformyblogmyblogresources_genimages线性回归算法.png" alt="线性回归" /></p>

<p>多元线性回归算法&ndash;即多特征的线性回归问题
<img src="D:somethingformyblogmyblogresources_genimages多元线性回归算法.png" alt="多元线性回归" /></p>

<h3 id="那么矩阵运算的作用-把大量的运算打包到一次矩阵运算中去">那么矩阵运算的作用！ 把大量的运算打包到一次矩阵运算中去！！</h3>

<p>使用梯度下降算法的小技巧</p>

<blockquote>
<p>1.特征缩放  Feature scaling<br />
对于特征值的区间相差很大的，其代价函数画出的图会很狭长(对于两个特征值，其图是狭长的椭圆)，这样找到的最优值的路径十分曲折，耗时。可以把特征值区间降到0到1(特征缩放)，
这样画出来的图比较圆滑，找的路径也比较快捷，梯度下降算法也能更快的收敛。
2.归一化  Mean normalization<br />
即在特征缩放之前，先用特征值Xi减去平均值ui。</p>
</blockquote>

<p>对于α学习率的值的大小的选择来说，<br />
太小，则收敛慢(slow convergence)<br />
太大，则随着迭代次数的增加，J(θ)可能不会下降(波动或上升)，并且有可能不会收敛(may not convergence)</p>

<p>那么如何选择合适的学习率？</p>

<h4 id="标准方程法-normal-equation">标准方程法(Normal equation)</h4>

<p>这里先给出定义：</p>

<p>设计矩阵(design matrix): X    和   向量Y</p>

<p>那么 套用θ=pinv(x&rsquo;*x)*x&rsquo;*y公式，即可求得合适的参数θ，使得代价函数最小。</p>

<h5 id="问题来了-我们知道pinv和inv操作是求矩阵的逆-如果所求矩阵不可逆怎么办">问题来了，我们知道pinv和inv操作是求矩阵的逆，如果所求矩阵不可逆怎么办？</h5>

<blockquote>
<p>出现这种问题有两个原因：<br />
1.所选的feature之间有线性关系，比如x1和x2都是代表房子的面积，只不过x1的单位是平方英尺，x2的单位是平方米，我们知道1米=3.28英尺<br />
2.选的feature太多了<br />
实际上，所求的矩阵不可逆的情况很少出现，所以基本不用担心！</p>
</blockquote>

<h4 id="octave基本语法">octave基本语法！</h4>

<blockquote>
<p>% 注释<br />
== 等于<br />
~= 不等于<br />
&amp;&amp; 逻辑与<br />
|| 逻辑或<br />
PS1(&lsquo;&gt;&gt; &lsquo;);   简化命令行<br />
；  可以抑制输出  比如 a=3 和a=3;  前者会在屏幕打印a=3，后者不会打印<br />
disp(a) 或者直接打a  可以打印出a的信息<br />
A=[1 2;3 4;5 6]    %定义一个3*2的矩阵A<br />
v=1:0.1:2  定义一个从1开始 ，每列元素增加0.1，只到增加到2的行向量<br />
v=1:6   即v=[1 2 3 4 5 6]<br />
ones(1,3)和zeros(1,3) 生成矩阵<br />
rand(1,3) 随机生成矩阵<br />
hist(w)  绘制直方图<br />
eye(4)  生成4阶单位矩阵<br />
help eye 显示帮助信息 按q退出</p>
</blockquote>

<p>###后记</p>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
  </body>
</html>
